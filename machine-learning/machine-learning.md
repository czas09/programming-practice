#   Machine Learning Outline

- - - - -

### cz

```
>   机器学习（machine learning，ML）

>   《机器学习》（西瓜书），周志华
>   《统计学习方法》，李航

>   二十世纪八十年代，符号学习
>   二十世纪九十年代以降，统计学习
>   统计学习，统计机器学习

>   假设样本数据独立同分布
>   迁移学习

>   1 机器学习基础知识：
>       基本概念与数学基础
>       模型评估与选择
>       线性模型
>   2 常用的机器学习方法：
>       决策树
>       神经网络
>       支持向量机
>       贝叶斯分类器
>       集成学习
>       聚类
>       降维与度量学习
>   3 机器学习的进阶知识
>       特征选择与稀疏学习
>       计算学习理论
>       半监督学习
>       概率图模型
>       规则学习
>       强化学习

>   0 机器学习基础：
>   基本术语
>   数学基础（大纲）：
>       微积分 / 分析学
>       代数学
>           线性代数（矩阵理论、特征值理论）
>           代数结构
>       概率论 / 数理统计
>       最优化
>       信息论
>       数理逻辑

>   1 模型评估与选择：
>   经验误差与过拟合
>   评估方法
>   性能度量
>   比较检验
>   偏差与方差

>   2 线性模型
>   基本形式
>   线性回归
>   对数几率回归
>   线性判别分析
>   类别不平衡问题

>   3 决策树：
>   基本流程
>   划分选择
>   剪枝处理
>   连续与缺失值 

>   4 神经网络：
>   神经元模型
>   感知机与多层网络
>   误差逆传播算法
>   全局最小与局部最小
>   其他常见神经网络
>   深度学习

>   5 支持向量机
>   基本概念：间隔与支持向量
>   对偶问题
>   核函数
>   软间隔与正则化
>   支持向量回归
>   核方法

>   6 贝叶斯分类器：
>   贝叶斯决策论
>   极大似然估计
>   朴素贝叶斯分类器
>   半朴素贝叶斯分类器
>   贝叶斯网
>   EM 算法

>   7 集成学习
>   个体与集成
>   Boosting
>   Bagging 与随机森林
>   结合策略
>   多样性

>   8 聚类
>   聚类任务
>   性能度量
>   距离计算
>   原型聚类
>   密度聚类
>   层次聚类

>   9 降维与度量学习
>   $k$ 近邻学习
>   低维嵌入
>   主成分分析
>   核化线性降维
>   流形学习
>   度量学习

>   10 特征选择与稀疏学习
>   子集搜索与评价
>   过滤式选择
>   包裹式选择
>   嵌入式选择与 $L_1$ 正则化
>   稀疏表示与字典学习
>   压缩感知

>   11 计算学习理论
>   基本概念
>   PAC 学习
>   有限假设空间
>   VC 维
>   Rademacher 复杂度
>   稳定性

>   12 半监督学习
>   未标记样本
>   生成式方法
>   半监督 SVM
>   图半监督学习
>   基于分歧的方法
>   半监督聚类

>   13 概率图模型
>   隐马尔可夫模型
>   马尔科夫随机场
>   条件随机场 
>   学习与推断
>   近似推断

>   14 规则学习
>   基本概念
>   序贯覆盖
>   剪枝优化
>   一阶规则学习
>   归纳逻辑程序设计

>   15 强化学习
>   任务与奖赏
>   $K-$摇臂赌博机
>   有模型学习
>   免模型学习
>   值函数近似
>   模仿学习

- - - - -

《统计学习方法》

>   0 统计学习基础知识
>   统计学习方法的分类
>       基本分类、按模型、按算法、按技巧

数据独立同分布
统计学习方法的步骤

输入空间、特征空间、输出空间
联合概率分布
假设空间：概率模型（用条件概率分布表示）、非概率模型（用决策函数表示）

>   统计学习方法的三个要素
>       模型、策略、算法

损失函数（loss function）或代价函数（cost function）
模型关于联合分布的期望损失
损失函数的分类：
    0-1 损失函数
    平方（quadratic）损失函数
    绝对（absolute）损失函数
    对数（logarithmic）损失函数或对数似然损失函数（log-likelihood loss function）
损失函数的期望Rexp，风险函数（risk function）或期望损失（expected loss）

经验风险Remp(f) 关于训练样本集的平均损失
经验风险最小化（ERM）、结构风险最小化（SRM）

ERM：
求解最优化问题
条件概率分布，对数损失函数：极大似然估计（maximum likelihood estimation）
引入过拟合问题

SRM：
正则化（regularization）
正则化项（regularizer）或惩罚项（penalty term）
贝叶斯估计中的最大后验概率估计
模型复杂度由模型的先验概率表示

>   模型评估与模型选择
>       训练误差与测试误差
>       过拟合与模型选择

训练误差、测试误差

>   模型选择：正则化与交叉验证
>   泛化能力
>       泛化误差与泛化误差上界
>   生成模型与判别模型

>   监督学习的应用：
>   分类问题
>   标注问题
>   回归问题

>   1 感知机
>   感知机模型
>   感知机学习策略
>   感知机学习算法

>   2 $k$ 近邻法
>   $k$ 近邻算法
>   $k$ 近邻模型
>   $k$ 近邻法的实现：$kd$ 树

>   3 朴素贝叶斯法
>   朴素贝叶斯法的学习与分类
>   朴素贝叶斯法的参数估计

>   4 决策树
>   决策树模型与学习
>   特征选择
>   决策树的生成
>   决策树的剪枝
>   CART 算法

>   5 Logistic 回归与最大熵模型
>   Logistic 回归模型
>   最大熵模型
>   模型学习的最优化算法

>   6 支持向量机
>   线性可分支持向量机与硬间隔最大化
>   线性支持向量机与软间隔最大化
>   非线性支持向量机与核函数
>   序列最小最优化算法

>   7 提升方法
>   AdaBoost 算法
>   AdaBoost 算法的训练误差分析
>   AdaBoost 算法的解释
>   提升树

>   8 EM 算法及其推广
>   EM 算法的引入
>   EM 算法的收敛性
>   EM 算法在高斯混合模型学习中的应用
>   EM 算法的推广

>   9 隐马尔可夫模型
>   隐马尔可夫模型的基本概念
>   概率计算方法
>   学习算法
>   预测算法

>   10 条件随机场
>   概率无向图模型
>   条件随机场的定义与形式
>   条件随机场的概率计算问题
>   条件随机场的学习算法
>   条件随机场的预测算法

>   11 监督学习方法的总结


0 无监督学习方法概述
0.1 无监督学习的基本原理
0.2 无监督学习的基本问题
0.3 无监督学习的三个要素
0.4 无监督学习方法

1 聚类方法
1.1 聚类方法的基本概念
1.2 层次聚类
1.3 $k$ 均值聚类

2 降维::奇异值分解
2.1 奇异值分解的定义与性质
2.2 奇异值分解的计算
2.3 奇异值分解与矩阵近似

3 降维::主成分分析
3.1 总体主成分分析
3.2 样本主成分分析

4 潜在语义分析
4.1 单词向量空间与话题向量空间
4.2 潜在语义分析算法
4.3 非负矩阵分解算法

5 概率潜在语义分析
5.1 概率潜在语义分析模型
5.2 概率潜在语义分析算法

6 马尔科夫链蒙特卡洛法
6.1 蒙特卡罗法
6.2 马尔科夫链
6.3 马尔科夫链蒙特卡洛法
6.4 Metropolis-Hastings 算法
6.5 吉布斯抽样

7 潜在狄利克雷分配
7.1 狄利克雷分布
7.2 潜在狄利克雷分配模型
7.3 LDA 的吉布斯抽样算法
7.4 LDA 的变分 EM 算法

8 PageRank 算法
8.1 PageRank 算法的定义
8.2 PageRank 算法的计算

9 无监督学习方法总结
```

```
机器学习与深度学习

烽火通信 IAO 李念

机器学习经典定义

预测、回归

CTR预测
NLP主题
垃圾邮件分类

无监督：
关联分析（Association Analysis）
Apriori
FP-Growth

GBRT
GBDT

XGBoost

数据流图（Data Flow Graph）

数据预处理（数据清洗、数据采样，上/下采样）直抽

工具：hive sql、spark sql

模型状态分析
模型融合

SQL 的分析函数 Oracle

特征工程【的一般流程框架
单个特征：归一化

过滤型
包裹型
嵌入型

卡方检验
F 检验等

sklearn
网格搜索（GridSearch）

Bagging 投票机制
模型stacking：模型融合
Adaboost、逐步增强树（Gradient Boost Tree）

不同算法做vote或求平均
用多种predictor结果作为特征训练

xgboost
lightbgm

智能问答

自动驾驶，图像预测         
语义分割
```

```

回归、分类，聚类与信息检索

核心技术
深度模型训练和优化技巧
深度学习五大模型
开源平台
基本框架结构
强化学习，深度强化学习
对抗生成网络（GAN）
迁移学习（TL）

结构化数据：
结构化数据，图像数据，时间序列和自然语言文本

金融相关的机器学习核心范式和算法

```

```
>   人工智能（Artificial Intelligence，AI）
>   模式识别（Pattern Recognition）
>   机器学习（Machine Learning，ML）
>   人工神经网络（Artificial Neural Network，ANN）
>   深度学习（Deep Learning，DL）

>   人工智能学派
>   机器学习学派

>   机器学习：
>   监督学习（Supervised Learning）：回归（Regression）任务、分类任务
>   无监督学习（Unsupervised Learning）：降维任务
>   增强学习（Reinforcement Learning）
> 
>   支持向量机（SVM）
>   Logistic 回归
>   决策树（Decision Tree）
>   贝叶斯网络
>   蒙特卡洛方法（Monte Carlo Method）
> 
>   统计模型
> 
>   过拟合与欠拟合、数据集的划分
>   数据集
> 
>   特征学习（feature learning）
>   表示学习（representation learning）

>   神经网络
> 
>   反向传播（backprop）
> 
>   卷积神经网络（Convolutional Neural Network，CNN）
> 
>   循环神经网络（Recurrent Neural Network，RNN）：LSTM
>   Encoder-Decoder
>   注意力（Attention）机制
>   自注意力
> 
>   生成对抗网络（GAN）
>   贝叶斯神经网络
>   图神经网络（Graph Neural Network，GNN）
>   脉冲神经网络

>   深度学习加速训练技术、优化技术
>   性能参数、loss、损失函数、泛化能力
>   最大熵原理
>   优化器：Adam 算法
>   工程方法：正则化（Regularization）、Batch Normalization、Dropout
>   核技巧（Kernel Trick）

>   深度学习的可解释性

>   计算机视觉（Computer Vision，CV）
>   图像算法

>   自然语言处理（Natural Language Processing，NLP）
>   自然语言理解（Natrual Language Understanding，NLU）
>   NLP 工具包、统计语言模型
>   预训练模型：Bert
>   多语言、中文信息处理

>   自动语音识别
>   Voice Activity Detection
> 
>   WaveNet
>   Tacotron 2

>   知识图谱（Knowledge Graph，KG）：信息抽取（Information Retrieval）关系抽取、命名实体识别（NER）
>   Probase
> 
>   推荐系统（Recommandation System）
>   聊天机器人（ChatBot）
>   问答系统

>   社会计算、人文计算、数字人文

>   迁移学习（Transfer Learning）
>   图网络学习：概率图模型、图嵌入
>   联邦学习（Federated Learning）

>   自动编码器（Autoencoder）

>   书籍：
>   MLAPP

>   深度学习编程与实现：
>   深度学习框架：Tensorflow、Keras、PyTorch
>   深度学习可视化（Visualization）

>   分布式机器学习
>   AutoML
```


```
机器学习（Machine Learning）

    Community
    书籍课程资料
    会议期刊
    工具框架
```